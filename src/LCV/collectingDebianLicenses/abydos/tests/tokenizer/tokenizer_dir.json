{
    "content": [
        {
            "hidden": false,
            "name": "__init__.py",
            "stat": {
                "perms": "rw-r--r--",
                "size": 848,
                "symlink_dest": null,
                "type": "-"
            },
            "type": "file"
        },
        {
            "hidden": false,
            "name": "test_tokenizer__tokenizer.py",
            "stat": {
                "perms": "rw-r--r--",
                "size": 6767,
                "symlink_dest": null,
                "type": "-"
            },
            "type": "file"
        },
        {
            "hidden": false,
            "name": "test_tokenizer_c_or_v_cluster.py",
            "stat": {
                "perms": "rw-r--r--",
                "size": 2957,
                "symlink_dest": null,
                "type": "-"
            },
            "type": "file"
        },
        {
            "hidden": false,
            "name": "test_tokenizer_character.py",
            "stat": {
                "perms": "rw-r--r--",
                "size": 3105,
                "symlink_dest": null,
                "type": "-"
            },
            "type": "file"
        },
        {
            "hidden": false,
            "name": "test_tokenizer_cv_cluster.py",
            "stat": {
                "perms": "rw-r--r--",
                "size": 2793,
                "symlink_dest": null,
                "type": "-"
            },
            "type": "file"
        },
        {
            "hidden": false,
            "name": "test_tokenizer_legalipy.py",
            "stat": {
                "perms": "rw-r--r--",
                "size": 3183,
                "symlink_dest": null,
                "type": "-"
            },
            "type": "file"
        },
        {
            "hidden": false,
            "name": "test_tokenizer_nltk.py",
            "stat": {
                "perms": "rw-r--r--",
                "size": 3827,
                "symlink_dest": null,
                "type": "-"
            },
            "type": "file"
        },
        {
            "hidden": false,
            "name": "test_tokenizer_q_grams.py",
            "stat": {
                "perms": "rw-r--r--",
                "size": 11651,
                "symlink_dest": null,
                "type": "-"
            },
            "type": "file"
        },
        {
            "hidden": false,
            "name": "test_tokenizer_q_skipgrams.py",
            "stat": {
                "perms": "rw-r--r--",
                "size": 23280,
                "symlink_dest": null,
                "type": "-"
            },
            "type": "file"
        },
        {
            "hidden": false,
            "name": "test_tokenizer_regexp.py",
            "stat": {
                "perms": "rw-r--r--",
                "size": 2640,
                "symlink_dest": null,
                "type": "-"
            },
            "type": "file"
        },
        {
            "hidden": false,
            "name": "test_tokenizer_saps.py",
            "stat": {
                "perms": "rw-r--r--",
                "size": 2282,
                "symlink_dest": null,
                "type": "-"
            },
            "type": "file"
        },
        {
            "hidden": false,
            "name": "test_tokenizer_sonoripy.py",
            "stat": {
                "perms": "rw-r--r--",
                "size": 2465,
                "symlink_dest": null,
                "type": "-"
            },
            "type": "file"
        },
        {
            "hidden": false,
            "name": "test_tokenizer_vc_cluster.py",
            "stat": {
                "perms": "rw-r--r--",
                "size": 2789,
                "symlink_dest": null,
                "type": "-"
            },
            "type": "file"
        },
        {
            "hidden": false,
            "name": "test_tokenizer_whitespace.py",
            "stat": {
                "perms": "rw-r--r--",
                "size": 2482,
                "symlink_dest": null,
                "type": "-"
            },
            "type": "file"
        },
        {
            "hidden": false,
            "name": "test_tokenizer_wordpunct.py",
            "stat": {
                "perms": "rw-r--r--",
                "size": 2611,
                "symlink_dest": null,
                "type": "-"
            },
            "type": "file"
        }
    ],
    "directory": "tokenizer",
    "package": "abydos",
    "path": "abydos/0.5.0+git20201231.344346a-3/tests/tokenizer",
    "pkg_infos": {
        "area": "main",
        "copyright": true,
        "ctags_count": 0,
        "license": "/copyright/license/abydos/0.5.0+git20201231.344346a-3/",
        "metric": {
            "size": 90684
        },
        "pts_link": "https://tracker.debian.org/pkg/abydos",
        "sloc": [
            [
                "python",
                75612
            ],
            [
                "makefile",
                226
            ]
        ],
        "suites": [
            "bookworm",
            "bullseye",
            "sid"
        ],
        "vcs_browser": "https://salsa.debian.org/python-team/packages/abydos",
        "vcs_type": "git"
    },
    "type": "directory",
    "version": "0.5.0+git20201231.344346a-3"
}